from AutoPrediction import PromptingFunctions
from AutoPrediction import AutoCoding
from AutoPrediction import CodeInterpreter
import copy

def SelfCorrectionForModelTraining(memory, error_message, GPT_model = "gpt-3.5-turbo", api_key = None, organization_id = None, max_iterations = 5, temperature = 0, time_interval = 20):
    """Correct wrong Python codes of model training using GPT.
    This function utilizes GPT to correct wrong Python codes of model training.
    
    Inputs
    ----------
    memory: Incorrect python code.
    error_message: Error messages of the code.
    max_iterations: Maximum number of self-correction. The default is 5.
    GPT_model: Name of the GPT model.
    api_key: Your API key of GPT.
    organization_id: Your organization id of GPT.
    temperature: Control the creativity of the responses generated by GPT. Higher values result in more randomness, while lower values make responses more focused and deterministic.
    time_interval: Minimum time interval between two calls of the GPT API (s).
    
    Outputs
    ----------
    result: Outputs of GPT-based code self-correction. There are 8 outputs in the results:
      corrected_code: Corrected code.
      model_accuracy: Model accuracy.
      n_iterations: Number of iterations for code correction.
      message: All chats between GPT and computers for code correction.
      total_completion_tokens: Total completion tokens of GPT.
      total_prompt_tokens: Total prompt tokens of GPT.
      total_response_time: Total response time of GPT (s).
      total_run_time_code: Total code run time (s).
    
    """
    
    n_iterations = 0
    total_completion_tokens = 0
    total_prompt_tokens = 0
    total_response_time = 0
    total_run_time_code = 0
    all_messgae = []
    
    while n_iterations < max_iterations:
        print(str(n_iterations+1)+" attempt for self-correction")
        Self_correction_prompt = PromptingFunctions.PromptingFunctionForSelfCorrection(error_message)
        coding_returncode, coding_output = AutoCoding.GPTCoding(prompt = Self_correction_prompt, memory = memory, GPT_model = GPT_model, api_key = api_key, organization_id = organization_id, temperature = temperature, time_interval = time_interval)
        
        if coding_returncode == 0:
            code = coding_output["code"]
            response_time = coding_output["response_time"]
            completion_tokens = coding_output["completion_tokens"]
            prompt_tokens = coding_output["prompt_tokens"]
            message = coding_output["message"]
            
            all_messgae.append(copy.deepcopy(message))
            total_completion_tokens += completion_tokens
            total_prompt_tokens += prompt_tokens
            total_response_time += response_time
            n_iterations += 1
            
            returncode, results = CodeInterpreter.CodeInterpreter(code)

            if returncode == 0: #The code runs successfully (returncode = 0).
                corrected_code = code
                model_accuracy = results["model_accuracy"]
                total_run_time_code += results["run_time_code"]
                
                result = {"corrected_code":corrected_code,
                          "model_accuracy": model_accuracy,
                          "n_iterations": n_iterations,
                          "message": all_messgae,
                          "total_completion_tokens": total_completion_tokens,
                          "total_prompt_tokens": total_prompt_tokens,
                          "total_response_time": total_response_time,
                          "total_run_time_code": total_run_time_code}
            
                return 0, result
            
            elif returncode == 1: #The code is still incorrect.
                error_message = results["error_message"]
                memory = [message[0], message[-1]]
                
            else: #The code interpreter breaks down (returncode = 1).
                result = {"corrected_code": None,
                          "model_accuracy": None,
                          "n_iterations": n_iterations,
                          "message": all_messgae,
                          "total_completion_tokens": total_completion_tokens,
                          "total_prompt_tokens": total_prompt_tokens,
                          "total_response_time": total_response_time,
                          "total_run_time_code": total_run_time_code}   
                
                return 1, result
                
        else: #GPT cannot response (returncode = 2).
            result = {"corrected_code": None,
                      "model_accuracy": None,
                      "n_iterations": n_iterations,
                      "message": all_messgae,
                      "total_completion_tokens": total_completion_tokens,
                      "total_prompt_tokens": total_prompt_tokens,
                      "total_response_time": total_response_time,
                      "total_run_time_code": total_run_time_code} 
            
            return 2, result
    
    if n_iterations == max_iterations: #GPT cannot correct wrong codes (returncode = 1).
        result = {"corrected_code": None,
                  "model_accuracy": None,
                  "n_iterations": n_iterations,
                  "message": all_messgae,
                  "total_completion_tokens": total_completion_tokens,
                  "total_prompt_tokens": total_prompt_tokens,
                  "total_response_time": total_response_time,
                  "total_run_time_code": total_run_time_code}   
        
        return 1, result
    
def SelfCorrectionForModelDeployment(memory, error_message, GPT_model = "gpt-3.5-turbo", api_key = None, organization_id = None, max_iterations = 5, temperature = 0, time_interval = 20):
    """Correct wrong Python codes of model deployment using GPT.
    This function utilizes GPT to correct wrong Python codes of model deployment.
    
    Inputs
    ----------
    memory: Incorrect python code.
    error_message: Error messages of the code.
    max_iterations: Maximum number of self-correction. The default is 5.
    GPT_model: Name of the GPT model.
    api_key: Your API key of GPT.
    organization_id: Your organization id of GPT.
    temperature: Control the creativity of the responses generated by GPT. Higher values result in more randomness, while lower values make responses more focused and deterministic.
    time_interval: Minimum time interval between two calls of the GPT API (s).
    
    Outputs
    ----------
    result: Outputs of GPT-based code self-correction. There are 8 outputs in the results:
      corrected_code: Corrected code.
      n_iterations: Number of iterations for code correction.
      message: All chats between GPT and computers for code correction.
      total_completion_tokens: Total completion tokens of GPT.
      total_prompt_tokens: Total prompt tokens of GPT.
      total_response_time: Total response time of GPT (s).
      predicted_load: Real-time prediction results.
      total_run_time_code: Total code run time (s).
    
    """
    
    n_iterations = 0
    total_completion_tokens = 0
    total_prompt_tokens = 0
    total_response_time = 0
    total_run_time_code = 0
    all_messgae = []
    
    while n_iterations < max_iterations:
        print(str(n_iterations+1)+" attempt for self-correction")
        Self_correction_prompt = PromptingFunctions.PromptingFunctionForSelfCorrection(error_message)
        coding_returncode, coding_output = AutoCoding.GPTCoding(prompt = Self_correction_prompt, memory = memory, GPT_model = GPT_model, api_key = api_key, organization_id = organization_id, temperature = temperature, time_interval = time_interval)
        
        if coding_returncode == 0:
            code = coding_output["code"]
            response_time = coding_output["response_time"]
            completion_tokens = coding_output["completion_tokens"]
            prompt_tokens = coding_output["prompt_tokens"] 
            message = coding_output["message"] 
            
            all_messgae.append(copy.deepcopy(message))
            total_completion_tokens += completion_tokens
            total_prompt_tokens += prompt_tokens
            total_response_time += response_time
            n_iterations += 1
            
            returncode, results = CodeInterpreter.CodeInterpreterModelDeployment(code)

            if returncode == 0: #The code runs successfully (returncode = 0).
                corrected_code = code
                total_run_time_code += results["run_time_code"]
                
                result = {"corrected_code":corrected_code,
                          "n_iterations": n_iterations,
                          "message": all_messgae,
                          "total_completion_tokens": total_completion_tokens,
                          "total_prompt_tokens": total_prompt_tokens,
                          "total_response_time": total_response_time,
                          "predicted_load": results["predicted_load"],
                          "total_run_time_code": total_run_time_code}
            
                return 0, result
            
            elif returncode == 1: #The code is still incorrect.
                error_message = results["error_message"]
                memory = [message[0], message[1], message[2], message[-1]]
            
            else: #The code interpreter breaks down (returncode = 1).
                result = {"corrected_code": None,
                          "n_iterations": n_iterations,
                          "message": all_messgae,
                          "total_completion_tokens": total_completion_tokens,
                          "total_prompt_tokens": total_prompt_tokens,
                          "total_response_time": total_response_time,
                          "predicted_load": None,
                          "total_run_time_code": total_run_time_code}   
                
                return 1, result
                
        else: #GPT cannot response (returncode = 2).
            result = {"corrected_code": None,
                      "n_iterations": n_iterations,
                      "message": all_messgae,
                      "total_completion_tokens": total_completion_tokens,
                      "total_prompt_tokens": total_prompt_tokens,
                      "total_response_time": total_response_time,
                      "predicted_load": None,
                      "total_run_time_code": total_run_time_code} 
            
            return 2, result
    
    if n_iterations == max_iterations: #GPT cannot correct wrong codes (returncode = 1).
        result = {"corrected_code": None,
                  "n_iterations": n_iterations,
                  "message": all_messgae,
                  "total_completion_tokens": total_completion_tokens,
                  "total_prompt_tokens": total_prompt_tokens,
                  "total_response_time": total_response_time,
                  "predicted_load": None,
                  "total_run_time_code": total_run_time_code}   
        
        return 1, result