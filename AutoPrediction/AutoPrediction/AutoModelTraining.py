from AutoPrediction import PromptingFunctions
from AutoPrediction import CodeInterpreter
from AutoPrediction import AutoCoding
from AutoPrediction import CodeSelfCorrection
import copy

def AutoModelTraining(X, GPT_model = "gpt-3.5-turbo", api_key = None, organization_id = None, temperature = 0):
    """Automated model training based GPT.
    This function utilizes GPT to generate Python codes of model training.
    
    Inputs
    ----------
    X: Input list for the prompting function. There are 19 elements in X:
      X[0]: Name of a file that stores historical data.
      X[1]: Available variable list in historical data.
      X[2]: Building energy load that needs to be predicted.
      X[3]: Missing data handling method.
      X[4]: Name list of hyper-parameters of the missing data handling method.
      X[5]: Value list of hyper-parameters of the missing data handling method.
      X[6]: Outlier identification method.
      X[7]: Name list of hyper-parameters of the outlier identification method.
      X[8]: Value list of hyper-parameters of the outlier identification method.
      X[9]: Data normalization method.
      X[10]: Name list of hyper-parameters of the data normalization method.
      X[11]: Value list of hyper-parameters of the data normalization method.
      X[12]: Feature engineering method
      X[13]: Name list of hyper-parameters of the feature engineering method.
      X[14]: Value list of hyper-parameters of the feature engineering method.
      X[15]: Data-driven model.
      X[16]: Name list of hyper-parameters of the data-driven model.
      X[17]: Value list of hyper-parameters of the data-driven model.
      X[18]: Model evaluation metric.
    GPT_model: Name of the GPT model.
    api_key: Your API key of GPT.
    organization_id: Your organization id of GPT.
    temperature: Control the creativity of the responses generated by GPT. Higher values result in more randomness, while lower values make responses more focused and deterministic.

    Outputs
    ----------
    result: Outputs of GPT-based automated model training. There are 8 outputs:
      total response time of GPT: Total response time of GPT (s).
      total completion tokens of GPT: Total completion tokens of GPT.
      total prompt tokens of GPT: Total prompt tokens of GPT.
      all messages of GPT: All chats between GPT and users in the step of automted model training.
      code: Code offered by GPT.
      code run time: Code run time (s).
      model accuracy: Model accuracy.
      n iterations: Number of iterations for code correction.
    
    """
    
    Pro = PromptingFunctions.PromptingFunctionForModelTraining(X)
    coding_returncode, coding_output = AutoCoding.GPTCoding(prompt = Pro, memory = [], GPT_model = GPT_model, api_key = api_key, organization_id = organization_id, temperature = temperature)
    
    if coding_returncode == 1: #GPT cannot response (returncode = 2).
        print("----------------------------------")
        print("Sorry! GPT cannot provie the code.")
        print("----------------------------------")
        
        result = {"total response time of GPT": coding_output["response_time"],
                  "total completion tokens of GPT": coding_output["completion_tokens"],
                  "total prompt tokens of GPT": coding_output["prompt_tokens"],
                  "all messages of GPT": [copy.deepcopy(coding_output["message"])],
                  "code": coding_output["code"],
                  "code run time": None,
                  "model accuracy": None,
                  "n iterations": None}
                
        return 2, result
    
    else: #GPT responses successfully.
        total_response_time = coding_output["response_time"]
        total_completion_tokens = coding_output["completion_tokens"]
        total_prompt_tokens = coding_output["prompt_tokens"]
        all_message = [copy.deepcopy(coding_output["message"])]
        code = coding_output["code"]
        interpreter_returncode, interpreter_output = CodeInterpreter.CodeInterpreter(code)
        
        if interpreter_returncode == 0: #The code runs successfully (returncode = 0).
            model_accuracy = interpreter_output["model_accuracy"]
            
            print("----------------------------------")
            print("Congratulation! The model accuracy is %0.2f"%model_accuracy)
            print("----------------------------------")
            
            result = {"total response time of GPT": total_response_time,
                      "total completion tokens of GPT": total_completion_tokens,
                      "total prompt tokens of GPT": total_prompt_tokens,
                      "all messages of GPT": all_message,
                      "code": code,
                      "code run time": interpreter_output["run_time_code"],
                      "model accuracy": interpreter_output["model_accuracy"],
                      "n iterations": None}
            
            return 0, result
            
        elif interpreter_returncode == 1: #The code needs to be corrected.
            print("----------------------------------")
            print("Sorry! The code need to be corrected.")
            print("----------------------------------")
            
            error_message = interpreter_output["error_message"]
            memory = coding_output["message"]
            self_correction_returncode, self_correction_output = CodeSelfCorrection.SelfCorrectionForModelTraining(memory = memory, error_message = error_message, GPT_model = GPT_model, api_key = api_key, organization_id = organization_id, temperature = temperature)
            
            code = self_correction_output["corrected_code"]
            model_accuracy = self_correction_output["model_accuracy"]
            n_iterations = self_correction_output["n_iterations"]
            message = self_correction_output["message"]
            all_message = all_message+copy.deepcopy(message)
            total_completion_tokens = total_completion_tokens+self_correction_output["total_completion_tokens"]
            total_prompt_tokens = total_prompt_tokens+self_correction_output["total_prompt_tokens"]
            total_response_time = total_response_time+self_correction_output["total_response_time"]
            total_run_time_code = self_correction_output["total_run_time_code"]
                
            if self_correction_returncode == 0: #The code is corrected successfully (returncode = 0).
                print("----------------------------------")
                print("Congratulation! The model accuracy after correction is %0.2f"%model_accuracy)
                print("----------------------------------")
                
                result = {"total response time of GPT": total_response_time,
                          "total completion tokens of GPT": total_completion_tokens,
                          "total prompt tokens of GPT": total_prompt_tokens,
                          "all messages of GPT": all_message,
                          "code": code,
                          "code run time": total_run_time_code,
                          "model accuracy": model_accuracy,
                          "n iterations": n_iterations}
                
                return 0, result
            
            elif self_correction_returncode == 2: #GPT cannot response (returncode = 2).
                print("----------------------------------")
                print("Sorry! GPT cannot provie the code.")
                print("----------------------------------")
                
                result = {"total response time of GPT": total_response_time,
                          "total completion tokens of GPT": total_completion_tokens,
                          "total prompt tokens of GPT": total_prompt_tokens,
                          "all messages of GPT": all_message,
                          "code": code,
                          "code run time": total_run_time_code,
                          "model accuracy": model_accuracy,
                          "n iterations": n_iterations}
                
                return 2, result   
            
            else: #GPT cannot correct the code (returncode = 1).
                print("----------------------------------")
                print("Sorry! The code cannot be corrected.")         
                print("----------------------------------")
                
                result = {"total response time of GPT": total_response_time,
                          "total completion tokens of GPT": total_completion_tokens,
                          "total prompt tokens of GPT": total_prompt_tokens,
                          "all messages of GPT": all_message,
                          "code": code,
                          "code run time": total_run_time_code,
                          "model accuracy": model_accuracy,
                          "n iterations": n_iterations}
                
                return 1, result                

        else: #Code cannot be implemented by the interpreter (returncode = 1).
            print("----------------------------------")
            print("Sorry! The code cannot run in Python interpreters.")
            print("----------------------------------")
            
            result = {"total response time of GPT": total_response_time,
                      "total completion tokens of GPT": total_completion_tokens,
                      "total prompt tokens of GPT": total_prompt_tokens,
                      "all messages of GPT": all_message,
                      "code": code,
                      "code run time": interpreter_output["run_time_code"],
                      "model accuracy": interpreter_output["model_accuracy"],
                      "n iterations": None}
            
            return 1, result

def Log(n_trial, returncode, results):
    """Write the automated model training results into a log file of automated model training.
    
    Inputs
    ----------
    n_trial: Current number of trial.
    returncode: Return code of automated model training.
    results: Results of automated model training.
        
    Outputs
    ----------
    n_trial: Next number of trial (n_trial plus 1).
    
    """
    
    with open("Log_AutoModelTraining.txt", 'a') as f:
        f.write("==========================================\n")
        f.write(f"Trial {n_trial}")
        f.write("\n")
        n_trial += 1
        f.write("------------------------------------------\n")
        f.write("Returncode: ")
        f.write(str(returncode))
        f.write("\n")
        f.write("------------------------------------------\n")
        f.write("Total response time of GPT: ")
        f.write(str(results["total response time of GPT"]))        
        f.write("\n")
        f.write("------------------------------------------\n")
        f.write("Total completion tokens of GPT: ")
        f.write(str(results["total completion tokens of GPT"]))        
        f.write("\n")
        f.write("------------------------------------------\n")
        f.write("Total prompt tokens of GPT: ")
        f.write(str(results["total prompt tokens of GPT"]))        
        f.write("\n")
        f.write("------------------------------------------\n")
        f.write("Code run time: ")
        f.write(str(results["code run time"]))
        f.write("\n")    
        f.write("------------------------------------------\n")
        f.write("Model accuracy: ")
        f.write(str(results["model accuracy"]))
        f.write("\n")   
        f.write("------------------------------------------\n")
        f.write("Number of iterations for code correction: ")
        f.write(str(results["n iterations"]))    
        f.write("\n")       
        f.write("------------------------------------------\n")
        f.write("Chats for coding and correction:\n")
        for n in range(len(results["all messages of GPT"])):
            f.write("-------------------\n")
            f.write(f"The {n}th chat:\n")
            for m in range(len(results["all messages of GPT"][n])):
                f.write("Role: ")
                f.write(str(results["all messages of GPT"][n][m]["role"]))
                f.write("\n")
                f.write("Content: ")
                f.write(str(results["all messages of GPT"][n][m]["content"]))
                f.write("\n")
            f.write("\n")
        f.write("==========================================\n")
        f.write("\n")
        
    return n_trial

def LogInitialization():
    """Iniitialize a log file of automated model training."""
    
    with open("Log_AutoModelTraining.txt", 'w') as f:
        f.write("AutoPrediction results:\n")
        f.write("\n")